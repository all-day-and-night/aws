S3(Simple Storage Service)
===========================

> 확정성, 데이터 가용성 및 보안과 성능을 제공하는 online Object(객체) storage service

> 구글 드라이브처럼 파일저장 서비스이며, 데이터를 온라인으로 object 형태로 저장하는 서비스

> 저비용, 저장 데이터 용량 높음

> elastic한 성질 때문에 별도의 스토리지 확장, 축소에 신경쓰지 않아도 됨

> FTP 서버처럼 단순한 파일 저장 영역으로 사용할 수 있으며, 다양한 aws 서비스의 사용로그저장, 정적 웹사이트 호스팅, ebs 스냅샷의 저장 영역 기능

> 빅데이터 분석의 데이터 소스로 활용, On-premise 환경의 재난복구 전용 데이터 백업, auto scaling을 활용한 ec2 인스턴스의 로그 저장 등오로 전세계적으로 폭 넓게 활용

> 지역별 서비스로 지역별 재난 상황에 대비하여 자동으로 반복 저장

# 사용 예

1. 클라우드 저장소(개인 파일 보관, 구글 드라이브처럼 사용가능)
2. 서비스의 대용량 파일 저장소 - 이미지, 동영상, 빅데이터(넷플릭스)
3. 서비스 로그 저장 및 분석
4. aws 아데나를 이용한 빅데이터 업로드 및 분석
5. 서비스 사용자의 데이터 업로드 서버(이미지 서버, 동영상 서버)
6. 중요한 파일은 ec2의 ssd(ebs: Elastic Block Storage)에 저장하지 말고 s3에 저장 
7. glacier와의 연동으로 비용 절감 및 규정 준수 가능(빙하라는 뜻으로 자주 쓰지않는 데이터를 s3에서 자동으로 변환)

# 버킷 / 객체

1. 객체(Object)는 데이터와 메타데이터를 구성하고 있는 저장 단위

2. 버킷(Bucket)은 이러한 객체를 저장하고 관리하는 역할

> 디렉토리 / 폴더 개념으로 키는 파일 명


# 암호화 

1. SSE-S3

> Amazon S3에 의해 관리되고 처리되는 키를 사용하여 암호화

> Server side에서 암호화

> AES-256 암호화 타입

> header: "x-amz-server-side-encryption": "AES256"

2. SSE-KMS

> AWS S3가 아니라 KMS에서 관리하고 처리하는 키를 사용한 암호화 방식

> 사용자의 접근 제어 가능 + audit trail(감사 추척 가능)

> header: "x-amz-server-side-encryption": "aws:kms"


3. SSE-C

> aws의 사용자에 의해 관리되는 server-side 키

> aws S3는 사용자가 제공하는 암호화 키를 저장하지 않는다.

> HTTPS 사용

> http 헤더에 client side data key를 담아 전송하고 object와 결합하여 암호화된 방식으로 s3 bucketd에 저장된다.

> 클라이언트 측에서 암호화 키를 제공하는 만큼 처리해야 할 로직과 책임이 더 많아진다.


4. Client Side Encryption(CSE)

> 클라이언트 라이브러리(S3 Encryption Client) 사용 / SDK

> 데이터를 저장하기 전에 암호화

> 데이터를 가져올 때에는 복호화

> aws sdk를 사용하여 키를 생성하고 클라이언트 단에서 암복호화 실시

> 저장 및 조회할 때는 암호화된 상태로 s3와 통신


# Bucket settings for Block Public Access

> public Access에 의해 정보가 누출 되는 것 방지

# Security

* Networking

> VPC Endpoint를 통해 public access 방지

* logging and audit

> S3 bucket에 logging 저장

> api calls는 aws CloudTrail에 log를 저장한다.

* Security

> MFA delete

> Pre0signed URLS: aws 자격증명으로 서명된 urls, 자격증명이 서명된 urls은 public access가능

# CORS

> Cross Origin Resource Sharing


# Access log

* Do Not set your logging bucket to be the monitored bucket, because of logging loop

# S3 Replcation (CRR & SRR)

## Cross Region Replication

1. use cases:

- compliance(규정 준수), lower latency access, replication across accounts(계정 간 복제)

## Same Region Replication

- log aggregation, live replication, between production and test accounts

* 복제 시 이전 object는 복제되지 않고 복제 설정 후 들어오는 object만 복제된다.

* replica bucket은 다시 replica를 만들 수 있지만, 복제가 연쇄적으로 일어나지 않는다.



## 복제 규칙은 삭제 사실까지는 복제하지 않는 것이 원칙


# S3 pre-signed URLs

- Can generate pre-signed URLs using SDK or CLI

> for Downloads (easy, can use the cli)
> for uploads (harder, must use the sdk)

```
# presign   default expiration time(1시간)
$ aws s3 presign s3://~~~ (url) --region "my-region"

# customize expiration time
$ aws s3 presign s3://~~~(url) --expires-in 300(sec) --region "my-region"
```


# S3 Storage Classes

1. Standard

> 고가용성으로 기능장애를 동시에 2개 버틸 수 있으므로 AZ 재해에 내성이 강함

> 빅데이터 분석, 모바일-게임 어플, 콘텐츠 배포에 사용

2. Intelligent-Tiering

> Same low latency and high troughput performance of S3 standard

> monthly cost of monitoring and auto-tiering fee

> 접근 패턴에 따라서 standard S3 와 s3 -IA사이에서 객체 이동...(이래서intelligent를 붙였구나)



3. Standard -IA

> 자주 접근하진 않지만 빠른 접근이 필요할 때 사용

> single AZ에 저장

> standard에 비해 적은 비용

> 2개의 동시 기능 재해에 대비

> 재해복구, 백업에 사용

4. One Zone -IA

> Standard IA와 같이 single AZ에 저장

> 고가용성 하지만 AZ에 재해가 일어나면 데이터 복구 x

> low latency and high throuohput performance

> Support SSL for data at transit and encryption at test

> lower cost compared to IA(by 20%)

> secondary backup copies of on-premise data, or storing data you can recreate

5. Glacier

> cold archive

> low cost object storage meant for archiving / backup

> data is retained for the longer term(10s of years)

> alternative to on-premise magnetic tape storage

> not bucket, archive

> archives are stored in "Vaults"(금고)

* 조회 옵션

- expedited(1 to 5 min)
- standard(3 to 5 hours)
- bulk(5 to 12 hours)

> 촤소 90 일 이상 저장


6. Glacier Deep Archive


* Deep Archive - for long term storage - cheaper

- standard (12hours)
- bulk(48 hours)
- 최소저장기간 180일

# 수명 주기(Life cycle)

> 일정 시간이 지났을 때 사용되지 않는 파일들을 삭제하거나 다른 곳에 백업

> ex) 새로운 버전 파일은 ~하고, 예전 버전 파일은 삭제해줘 라는 스크립트

> S3 버저닝 기능과 연동이 가능하며, 예전 버전과 현재 버전에 대해 설정 가능

> 업로드 / 삭제 / 업데이트 되었을 때 lambda 호출 가능

# Athena

> serverless query service s3

> query + analyze

> serverless SQL + analyze data 

> S3에 저장된 데이터를 간편하게 분석할 수 있고 몇 초안에 대용량 데이터 조회 가능

> 데이터가 저장되어 있는 s3를 설정해주고 테이블 생성 후 쿼리 실행하면 데이터 가져올 수 있다. 

> 파일을 load하고 압축을 풀지 않아도 되고 sql문을 통해 제약 조건을 걸어 원하는 데이터만 가져올 수 있다.


